#!/usr/bin/env python
# Let's test some LDA

import unittest
import lda

#A basic binary (not lda -based) topic distro between 3 topics

basic_link_model = { 'a':['1','2','3','4'],
        'b':['5','6','7','8'],
        'c':['9','10','11'] }

#I'm not putting these in files because I don't want to.
rec_titles_and_abstracts = [("UTA-Rec: a recommender system based on multiple criteria analysis", "UTARec, a Recommender System that incorporates Multiple Criteria Analysis methodologies is presented. The system's performance and capability of addressing certain shortfalls of existing Recommender Systems is demonstrated in the case of movie recommendations. UTARec's accuracy is measured in terms of Kendall's tau and ROC curve analysis and is also compared to a Multiple Rating Collaborative Filtering (MRCF) approach. The results indicate that the proposed Multiple Criteria Analysis methodology can certainly improve the recommendation process by producing highly accurate results, from a user oriented perspective."),("The information cost of manipulation-resistance in recommender systems", "Attackers may seek to manipulate recommender systems in order to promote or suppress certain items. Existing defenses based on analysis of ratings also discard useful information from honest raters. In this paper, we show that this is unavoidable and provide a lower bound on how much information must be discarded. We use an information-theoretic framework to exhibit a fundamental tradeoff between manipulation-resistance and optimal use of genuine ratings in recommender systems. We define a recommender system to be (n, c)-robust if an attacker with n sybil identities cannot cause more than a limited amount c units of damage to predictions. We prove that any robust recommender system must also discard units of useful information from each genuine rater."), ("The value of personalised recommender systems to e-business: a case study","Recommender systems have recently grown in popularity both in e-commerce and in research. However, there is little, if any, direct evidence in the literature of the value of recommender systems to e-Businesses, especially relating to consumer packaged goods (CPG) sold in a supermarket setting. We have been working in collaboration with LeShop (www.LeShop.ch), to gather real evidence of the added business value of a personalised recommender system. In this paper, we present our initial evaluation of the performance of our model-based personalised recommender systems over the 21-month period from May 2006 to January 2008, with particular focus on the added-value to the business. Our analysis covers shopper penetration, as well as the direct and indirect extra revenue generated by our recommender systems. One of the key lessons we have learnt during this case study is that the effect of a recommender system extends far beyond the direct extra revenue generated from the purchase of recommended items. The importance of maintaining updated model files was also found to be key to maintaining the performance of such model-based systems."), ("Recommendation as classification: using social and content-based information in recommendation", "Recommendation systems make suggestions about artifacts to a user. For instance, they may predict whether a user would be interested in seeing a particular movie. Social recomendation methods collect ratings of artifacts from many individuals, and use nearest-neighbor techniques to make recommendations to a user concerning new artifacts. However, these methods do not use the significant amount of other information that is often available about the nature of each artifact - such as cast lists o r movie reviews, for example. This paper presents an inductive learning approach to recommendation that is able to use both ratings information and other forms of information about each artifact in predicting user preferences. We show that our method outperforms an existing social-filtering method in the domain of movie recommendations on a dataset of more than 45,000 movie ratings collected from a community of over 250 users."), ("Collaborative Filtering Recommendation Algorithm Based on Cloud Model Clustering of Multi-indicators Item Evaluation", "Collaborative filtering recommendation algorithm is a personalized recommendation algorithm that is used widely in e-commerce recommendation system. In this paper, a collaborative filtering recomendation algorithm based on cloud model clustering of multi-indicators item evaluation is proposed. In the algorithm, the item evaluation is the object, time weighted function is introduced to item evaluation, soft culsters item based on cloud model and gets the recommended items. The algorithm solves problems of data updating and history validity of evaluation in the collaborative filtering algorithm. Soft cluster item based on cloud model is achieved to avoid the defects bringed by hard division.")]

topics_titles_and_abstracts = [("Unsupervised topic modelling for multi-party spoken discourse","We present a method for unsupervised topic modelling which adapts methods used in document classification (Blei et al., 2003; Griffiths and Steyvers, 2004) to unsegmented multi-party discourse transcripts. We show how Bayesian inference in this generative model can be used to simultaneously address the problems of topic segmentation and topic identification: automatically segmenting multi-party meetings into topically coherent segments with performance which compares well with previous unsupervised segmentation-only methods (Galley et al., 2003) while simultaneously extracting topics which rate highly when assessed for coherence by human judges. We also show that this method appears robust in the face of off-topic dialogue and speech recognition errors."), ("Video topic modelling with behavioural segmentation", "Topic models such as Latent Dirichlet Allocation (LDA) are used extensively for modelling multi-object behaviour and anomaly detection in busy scenes. However, existing topic models suffer from the sensitivity problem, where they are unable to detect anomalies that are mixed in with large numbers of co-occurring normal behaviours. Also at issue is the localisation problem, where anomalies are detected but not localised within a given video clip. To address these two problems this paper proposes a novel region LDA model, which encodes the spatial awareness that is ignored by conventional topic models. Both scene decomposition and behavioural modelling are simultaneously performed. Consequentially, abnormality is detected per-region rather than for the entire scene, resolving both the sensitivity and localisation issues. Experiments conducted on busy real world scenes demonstrate the superiority of the proposed model."),("    A multi-collection latent topic model for federated search","Collection selection is a crucial function, central to the effectiveness and efficiency of a federated information retrieval system. A variety of solutions have been proposed for collection selection adapting proven techniques used in centralised retrieval. This paper defines a new approach to collection selection that models the topical distribution in each collection. We describe an extended version of latent Dirichlet allocation that uses a hierarchical hyperprior to enable the different topical distributions found in each collection to be modelled. Under the model, resources are ranked based on the topical relationship between query and collection. By modelling collections in a low dimensional topic space, we can implicitly smooth their term-based characterisation with appropriate terms from topically related samples, thereby dealing with the problem of missing vocabulary within the samples. An important advantage of adopting this hierarchical model over current approaches is that the model generalises well to unseen documents given small samples of each collection. The latent structure of each collection can therefore be estimated well despite imperfect information for each collection such as sampled documents obtained through query-based sampling. Experiments demonstrate that this new, fully integrated topical model is more robust than current state of the art collection selection algorithms."),("Towards Semantic Wikis: Modelling Intensions, Topics, and Origin in Content Management Systems","Content management is the process of handling information within an organization or community. Therefore, content management systems have to provide generic functionality for generation, extraction, storage, and exchange of digital assets. Because of the heterogeneity and complexity of content, a sufficient semantical and user-oriented annotation of content is crucial. Although semantical annotation by metadata and ontologies together with reasoning support has been extensively studied for a long time, commercially available content management systems provide only basic support for semantic modelling. Conceptual aspects of content users and support of user specific intensions are neglected. In this paper we will analyze the mismatch between the requirements of content management and semantical description and propose a data model for content which treats semantic information not only as describing metadata but incorporates the data itself, the intension behind the data, the usage of data and the origin of data on the same level.")]

def create_docs_for_ta(title_abstract_list):
    for t_a in title_abstract_list:
        title, abstract = t_a
        yield create_test_doc(title, abstract, [], [])

def create_doc(title, abstract, references, citations):
    return {'id' : 13, 'title':title, 'abstract':abstract, 'references':references,'citations':citations}

class TestLDA(unittest.TestCase):
    def setUp(self):
        # set up the test classes, yo
        self.lda = lda.TopicModeller()

    def test_concats_ref_and_cite_correctly(self):
        normal_doc = create_doc("test","document",['adoc', 'b', 'c'], ['d'])
        result = self.lda.map_to_citation(normal_doc)

        self.assertEqual(result['id'], 13)
        self.assertEqual(result['document'], "adoc b c d")

        sad_doc  = create_doc("feel", "that sadness", [] ,  [])
        sad_result = self.lda.map_to_citation(sad_doc)

        self.assertEqual(sad_result['id'], 13)
        self.assertEqual(sad_result['document'], "")

    def test_concats_title_abst_correctly(self):
        normal_doc = create_doc("abst", "title", [], [])
        result = self.lda.map_to_abst(normal_doc)

        self.assertEqual(result['id'], 13)
        self.assertEqual(result['document'], "abst title")

        title_only = create_doc("title", "", [], [])
        title_result = self.lda.map_to_abst(title_only)

        self.assertEqual(title_result['id'], 13)
        self.assertEqual(title_result['document'], "title")


        abstract_only= create_doc("", "abstract", [], [])
        abstract_result= self.lda.map_to_abst(abstract_only)

        self.assertEqual(abstract_result['id'], 13)
        self.assertEqual(abstract_result['document'], "abstract")

        nothing_lol= create_doc("", "", [], [])
        nothing_result= self.lda.map_to_abst(nothing_lol)

        self.assertEqual(nothing_result['id'], 13)
        self.assertEqual(nothing_result['document'], "")












